{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Spark MLlib and ML\n",
    "\n",
    "In this notebook, we will see the main capabilities of Spark MLlib and ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark-MLlib-ML\").master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MLlilb\n",
    "\n",
    "In this section, we will focus on MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector, SparseVector\n",
    "from pyspark.mllib.feature import HashingTF, Word2Vec, IDF, StandardScaler, ChiSqSelector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib Feature Encoding and Data Preparation\n",
    "\n",
    "#### Working with Spark Vectors\n",
    "\n",
    "We can create Dense Vectors, Sparse Vectors and Labeled Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_vector = DenseVector(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 2.0, 3.0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vector = SparseVector(4, {0:1.5, 2:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 1.5, 2: 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_point = LabeledPoint(1, dense_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, [1.0,2.0,3.0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Textual Data\n",
    "\n",
    "We can also prepare text data using some in-built data transformations capabilities already included in MLlib. We first prepare some text data about Spam and Non-Spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_data = spark.read.csv(\"../data/spam.csv\", header=True)\n",
    "ini_data_rdd = ini_data.select([\"label\", \"text\"]).rdd.filter(lambda row: (isinstance(row.label, str) and isinstance(row.text, str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5573"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_data_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label='ham', text='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_data_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = ini_data_rdd.map(lambda x: x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the `HashingTF` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasing_TF(text_rdd):\n",
    "    \"\"\"\n",
    "    Transforms an input RDD of text using the Hashing TF transformer\n",
    "    \n",
    "    :input text_rdd: input RDD\n",
    "    :return: transformed RDD\n",
    "    \"\"\"\n",
    "    tokenizer = HashingTF()\n",
    "    text_tokenized = text_rdd.map(lambda text: text.split(\" \"))\n",
    "    return tokenizer.transform(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_text = hasing_TF(text_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(1048576, {79172: 1.0, 244892: 1.0, 296409: 1.0, 312753: 1.0, 384022: 1.0, 407924: 1.0, 414297: 1.0, 442668: 1.0, 627241: 1.0, 639697: 1.0, 799074: 1.0, 856522: 1.0, 897134: 1.0, 901549: 1.0, 968035: 1.0, 988036: 1.0, 997716: 1.0, 1015964: 1.0, 1033917: 1.0, 1044354: 1.0})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_text.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasing_TF_with_text(text_rdd):\n",
    "    \"\"\"\n",
    "    Transforms an input RDD of text using the Hashing TF transformer\n",
    "    keeping also the original text\n",
    "    \n",
    "    :input text_rdd: input RDD\n",
    "    :return: transformed RDD\n",
    "    \"\"\"\n",
    "    tokenizer = HashingTF()\n",
    "    return text_rdd.map(lambda text: (text, tokenizer.transform(text.split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_text_perserving = hasing_TF_with_text(text_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "  SparseVector(1048576, {79172: 1.0, 244892: 1.0, 296409: 1.0, 312753: 1.0, 384022: 1.0, 407924: 1.0, 414297: 1.0, 442668: 1.0, 627241: 1.0, 639697: 1.0, 799074: 1.0, 856522: 1.0, 897134: 1.0, 901549: 1.0, 968035: 1.0, 988036: 1.0, 997716: 1.0, 1015964: 1.0, 1033917: 1.0, 1044354: 1.0}))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_text_perserving.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `Word2Vec` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenized = text_rdd.map(lambda text: text.split(\" \"))\n",
    "word2vec_trformer = Word2Vec().fit(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0615, 0.0713, 0.007, 0.0284, -0.0985, 0.0336, -0.0257, -0.0536, -0.0093, -0.0124, 0.0267, 0.0514, -0.0384, -0.0138, -0.0179, 0.0149, 0.0856, 0.0339, 0.0404, 0.0404, -0.0049, 0.0279, 0.0037, -0.0256, -0.031, -0.0083, 0.015, 0.0343, -0.1048, 0.0421, -0.0407, 0.024, -0.0908, -0.0367, 0.0241, 0.0047, -0.0095, -0.0495, -0.008, -0.0256, 0.0476, 0.0263, 0.0257, -0.0465, -0.0003, -0.0809, -0.0349, 0.0294, 0.02, -0.0207, 0.0515, 0.1077, -0.0712, 0.0291, -0.0226, -0.0408, -0.0062, -0.0055, 0.0221, 0.0365, 0.0116, 0.0146, -0.0936, -0.0651, 0.051, -0.0737, -0.0549, 0.0181, 0.1016, 0.0163, -0.0028, -0.0397, -0.0022, 0.0374, -0.0237, -0.0181, 0.0115, 0.0491, 0.0739, -0.0107, -0.0571, -0.0524, 0.0479, -0.0372, 0.0198, -0.004, 0.0157, -0.126, 0.0621, -0.0406, 0.0106, -0.0118, 0.0182, 0.0248, 0.0692, 0.0696, -0.0893, -0.0955, 0.0262, -0.0346])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_trformer.transform(\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0557, 0.024, 0.0241, 0.0173, -0.0448, 0.0286, -0.0071, -0.0053, 0.0154, -0.0092, 0.0136, 0.0356, -0.0232, 0.0009, -0.0107, 0.0118, 0.0201, 0.0304, -0.0134, -0.0077, 0.0211, 0.0231, 0.0191, -0.0143, -0.0117, -0.0044, 0.0135, 0.0265, -0.0447, 0.0147, 0.0015, 0.017, -0.0651, 0.0009, 0.0071, -0.0066, 0.0074, -0.0402, -0.0048, -0.0111, 0.0163, 0.0359, -0.0114, -0.0438, 0.003, -0.0076, -0.014, 0.0112, 0.0141, -0.0088, 0.0001, 0.0567, -0.0418, 0.0409, 0.0102, -0.0033, -0.0002, 0.0052, -0.0323, -0.0246, -0.0198, 0.0169, -0.0493, -0.0073, 0.0369, -0.0333, -0.0033, 0.0423, 0.0146, -0.0001, -0.0288, 0.0172, -0.0203, -0.0104, 0.0234, 0.0379, 0.0221, -0.0023, 0.0242, -0.0177, -0.0407, 0.0052, 0.0065, 0.0045, 0.0062, -0.0159, 0.0089, -0.0404, -0.0142, -0.0189, 0.0145, 0.0105, 0.0269, -0.0075, 0.0249, 0.0253, 0.0016, -0.0526, 0.0041, 0.0149])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_trformer.transform(\"Free\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data for Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = HashingTF(1000)\n",
    "tf_vectors = tf.transform(text_rdd)\n",
    "idf = IDF()\n",
    "idf_model = idf.fit(tf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_text = ini_data_rdd.filter(lambda row: row.label == \"spam\").map(lambda row: row.text.split(\" \"))\n",
    "gen_text = ini_data_rdd.filter(lambda row: row.label != \"spam\").map(lambda row: row.text.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_points = idf_model.transform(tf.transform(spam_text)).map(lambda x: LabeledPoint(1, x))\n",
    "gen_points = idf_model.transform(tf.transform(gen_text)).map(lambda x: LabeledPoint(0, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_ini = spam_points.union(gen_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = ml_data_ini.map(lambda row: (randint(0,100), row)).sortByKey().map(lambda row: row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_train, ml_data_test = ml_data.randomSplit(weights = [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[54] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_train.cache()\n",
    "ml_data_test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling and Selection\n",
    "\n",
    "It is useful sometimes for the ML algorithms to scale that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler()` --> to scale numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler_model = std_scaler.fit(ml_data.map(lambda lpoint: lpoint.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = ml_data_train.map(lambda lpoint: lpoint.label)\n",
    "test_label = ml_data_test.map(lambda lpoint: lpoint.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_train_scl = train_label.zip(std_scaler_model.transform(ml_data_train.map(lambda lpoint: lpoint.features)))\\\n",
    ".map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "\n",
    "ml_data_test_scl = test_label.zip(std_scaler_model.transform(ml_data_test.map(lambda lpoint: lpoint.features)))\\\n",
    ".map(lambda x: LabeledPoint(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (1000,[18,133,184,278,390,403,411,421,574,581,630,637,706,783,789,807,808,821,822,824,937],[9.10145635512,17.4260213968,9.45472540734,8.56298964927,7.26691923942,7.04358538035,13.2336916489,6.52034068072,5.96542617781,7.18167686177,16.3198325861,5.32568093583,8.68433762659,2.87708423949,7.76209066016,6.2349925733,7.79493378756,5.37756847208,13.4442310562,9.65846657093,11.5576716992]))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_train_scl.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (1000,[7,69,75,120,222,274,289,304,317,323,365,369,407,431,442,619,631,658,807,882,903,939,974,979],[14.668435857,4.1679073928,11.8409552489,7.6794964018,3.14936680147,7.96797003614,5.58238396494,4.26629506314,3.69603215981,3.72785424961,1.4119082138,14.6735203427,15.9460499929,11.0516323062,8.15313602093,10.4969379283,8.00709362589,8.11210138222,6.2349925733,8.06317518116,3.47586227908,10.7070843704,8.50572058869,15.5969494943]))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_test_scl.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ChiSqSelector` --> to select the most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ChiSqSelector(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_model = selector.fit(ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.feature.ChiSqSelectorModel at 0x7f081c902b38>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_train_sel = train_label.zip(selector_model.transform(ml_data_train.map(lambda lpoint: lpoint.features)))\\\n",
    ".map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "\n",
    "ml_data_test_sel = test_label.zip(selector_model.transform(ml_data_test.map(lambda lpoint: lpoint.features)))\\\n",
    ".map(lambda x: LabeledPoint(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (100,[38,82,85],[8.62586820804,0.993951694971,2.46045035381]))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_train_sel.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (100,[7,21,23,25,28,34,91,94],[8.62586820804,8.62586820804,8.62586820804,0.281950403648,2.13362837302,8.62586820804,2.04245898588,0.0771763495663]))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_test_sel.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib Model Training\n",
    "\n",
    "Once we have prepared our data, we can train some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionWithLBFGS()\n",
    "lr_model_raw = lr.train(ml_data_train)\n",
    "lr_model_scl = lr.train(ml_data_train_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-2.0286, -1.5938, -2.5886, -0.9297, 0.4722, 12.5765, -0.0328, -5.8304, 0.1055, -4.1027, -4.4149, -3.3053, -2.1944, -2.6413, 0.1863, -0.8475, -3.0515, -0.7292, 0.4193, 2.9482, -1.0132, -2.9988, -2.6662, -4.4446, -2.4757, -6.8648, 5.6551, -0.6961, -1.2052, -2.3798, -2.7594, 17.8123, -2.7697, -0.54, -2.4009, -0.9642, -1.6688, -2.4287, 1.0176, 0.7415, -3.9635, 3.7422, -2.4016, -2.3644, -0.6487, 6.4751, 1.8152, -5.9118, 0.3514, 1.3409, -3.8598, 3.9975, -1.7918, -3.5499, -0.0916, -0.4125, -2.7814, -1.1816, -1.9391, 0.0198, 3.8314, 9.2274, -5.6853, -0.219, -2.2424, -3.1851, -2.59, -1.2827, -1.8992, 0.5443, 3.3486, 0.7074, 5.4672, 0.2179, -0.3228, 0.0619, 1.5158, -0.5706, -3.1794, -1.3888, -0.1108, -0.7209, -0.2748, -3.7414, -4.6501, 1.5655, -5.4361, -0.144, 1.3585, -2.5042, -2.9415, -2.8706, 6.9286, 1.4492, 1.3242, -2.8814, -2.1288, 10.621, -0.0668, 0.7018, -2.5423, 1.3878, -1.3022, -2.3315, -143.0627, 7.6571, -2.3749, 0.5491, 1.537, -0.8569, -0.3188, 8.0032, 0.6858, 1.1312, -1.284, -4.2121, 0.645, 0.9612, -46.3025, 0.6857, 0.9869, -13.5941, -0.8318, -1.8736, 5.3133, 4.1047, -4.6881, 6795.9173, -3.7282, 1.0087, -1.7166, -2.5816, 0.3872, -2.1617, -2.9182, -4.9804, -106.7142, 0.8031, -2.0055, 0.0357, -1.1452, 1.7632, 4.5365, -0.702, -0.2148, -3.6861, 1.8854, 1.3275, -2.4936, -27.6442, 3.3346, 1.2267, -42.676, 4.1994, -0.0343, 2.3806, -0.1951, -4.207, -15.7509, 4.3634, 6.1201, -1.2931, 2.9438, -3.469, 2.4635, -6.5606, -1.3412, 1.8066, -0.9741, 1.6519, 2.4139, -1.6312, 5.0652, -0.3568, -2.0765, -1.1187, -1.8527, 3.8439, -1.82, 7.73, -0.9203, 0.7938, -5.3032, -23.6253, -0.4333, 5.7233, -2.7066, 4.2923, -2.6079, -0.3008, -2.2725, -0.5624, 5.473, -4.4663, 0.432, -0.2637, -1.967, -2.1076, -2.2263, 0.0836, -0.4625, -128.1362, -4.9309, -1.2113, 2.8205, -2.8638, -1.4979, -4.6401, 3.6024, -2.1936, -4.0636, -4.4324, 0.9695, 2.5554, -0.8579, 4.6366, -1.851, 1.8669, -0.0169, -8.5846, 0.4288, -2.3174, 2.1165, -0.9374, -2.1081, -2.16, 1.5662, -0.4793, 1.1144, -4.5577, -0.8707, -5.4238, -1.8735, -0.2904, -1.8899, -1.1441, -0.2305, 1.7356, -2.9616, -2.6205, 1.4915, 0.4081, 0.5114, 1.2326, 0.7459, -0.5919, -0.264, 2.8096, -2.5427, -5.5797, -1.734, -1.1314, -2.8915, -3.0647, 7.1644, -0.2218, -1.3118, -1.1086, 1.1602, -7.2649, -2.1838, 5.1773, -3.899, -0.8444, -222.5448, 3.507, -1.8453, -2.4204, -2.2963, 3.7231, -2.1652, -1.9817, 1.5887, 0.4652, 2.9378, -2.4109, 0.324, 2.9508, 2.0633, -2.4935, -17.0133, 3.4001, -0.911, -3.3943, -1.0124, -2.4283, 4.9867, 3.4048, 1.6293, 139.3963, -0.4033, -0.8002, -6.5435, -1.556, -2.8576, 2.8882, -3.5389, -0.7183, 0.9884, 1.2448, 0.681, 5.17, 0.9698, 1.303, 7.4304, -1.0279, -1.1093, -0.496, -0.9575, 2.4769, 2.9181, -95.1758, -2.0865, -0.6188, -3.0883, -3.3119, -2.3525, -0.3471, -0.5177, -6.0812, 0.1279, -0.4452, -1.5638, -1.624, 6.372, 3.5366, 0.5387, -2.4677, -4.7835, -0.7342, -2.259, 1.695, -2.1978, 3.6361, 0.6315, 2.3255, -1.3888, -3.2745, -3.0497, 0.3656, 3.3326, 1.1844, 0.7959, 5.7995, -2.0447, -0.8708, 2.9987, 1.1008, -2.4044, -5.5626, 0.2465, -5.6927, 3.1806, 7.0492, -0.0915, -4.1606, 3.2555, -4.9695, -0.2556, 2.8841, 0.5925, -4.9283, -1.8133, -293.7969, 1.7129, 1.4147, 3.2344, 0.2428, -0.2722, 1.7932, -2.294, -2.1507, -3.9596, -0.1427, -1.643, 2.8452, 1.8953, -1.2836, 2.7929, -3.1175, 3.5535, -2.71, -0.2692, -2.5325, -0.9701, -2.1608, 4.9243, -1.7246, 1.2966, 2.1202, 2.7806, -5.0778, -0.8618, -5.4614, -5.6618, 0.0711, -1.8699, -0.0593, -1.3765, -1.1151, -3.1228, -1.4, -1.0617, -1.467, -3.4608, 0.751, 3.3996, -2.515, -2.6288, -1.9513, 6.5763, -0.3753, 2.4324, 1.6511, -0.2991, 8.1481, -3.8297, 1.6981, -3.6079, -1.4005, -1.7224, -0.4111, -5.2149, -2.7118, 0.8299, -0.3194, 2.9004, -1.5081, -2.0177, 0.079, -1.1819, 0.6492, -1.9778, 2.1541, -2.0782, -3.3371, 9.2622, -2.0329, 2.1686, 8.6664, 3.77, -1.0622, 0.4412, -4.2356, 7.8475, -2.3853, -5.22, -3.7499, -3.6218, 1.8365, -2.6159, -2.2634, -2.5492, 0.0629, 0.6891, -2.8022, 2.847, -0.5924, -2.2306, 1.7677, -0.4593, 0.1774, 1.5045, -3.4854, 0.023, -3.2128, -3.2956, 0.3749, -3.599, -2.162, -0.3721, 3.7032, -1.2613, -2.2113, -1.7169, 3.5353, -0.1817, 7.0736, -1.3377, -2.4978, 2.4753, 0.9017, -8.6369, 4.1866, -0.3634, -1.1991, 0.169, -7.1562, -4.8275, -0.8434, -2.2804, -11.0931, 0.8446, 2.8991, -0.5398, -4.46, 1.709, -2.2473, -0.8593, 0.1399, 0.292, 1.6829, 0.4915, -6.8483, 0.8101, -3.4707, -4.8712, -4.4604, 29.7008, -3.9617, 2.614, -6.8917, 3.4127, -1.7795, -1.7196, -1.029, -5.7107, -0.1611, -1.8642, -0.9045, 2.0007, -2.7848, 0.7984, 5.928, -29.7775, -1.0931, 0.1515, 0.3673, -2.1761, -2.9229, -1.4962, -0.9148, 1.1577, -3.175, -0.036, 0.2727, 0.0974, 2.2427, -5.2199, -2.0798, -0.7343, -0.3259, -2.131, -7.3514, 1.7314, -1.6895, 2.2066, 0.2725, 2.931, -6.2854, 0.1135, -1.2552, -1.6213, 1.0383, 2.3928, -1.5808, -74.2434, -1.7727, 0.4375, 4.373, -5.8038, 3.7222, 0.2142, 0.8524, 0.9174, -4.1653, -1.9293, 5.0424, -86.1191, 4.3655, 2.7012, 0.4868, -3.1458, -3.5839, -1.2024, 1.0588, 0.1472, -4.0919, -2.3699, -2.9479, 0.8723, -7.9089, 3.7981, -0.3849, 0.3929, -0.4666, -4.7538, 1.0193, -4.4871, -1.6189, 0.4742, -4.4603, 0.5239, -0.4739, 0.6907, 0.6566, -0.7908, -0.32, 4.9159, -3.2737, -0.9621, -0.9195, 1.8991, 7.1535, -2.4298, -1.1942, 0.553, -0.7637, 2.5828, -0.6737, 10.4359, 1.8158, 0.3939, 3.7042, 0.0967, 1.4933, -0.4243, -1.5398, -1.9952, -2.0345, -0.0073, -0.698, -4.8832, 0.4661, 2.3339, -0.897, 8.4652, -1.9933, 0.8749, 0.7313, 4.0357, -0.3983, -1.1631, 7.1757, 1.9992, -1.4007, -1.6696, -1.862, -0.6612, -4.2279, 3.5204, -0.2959, -0.342, -2.0488, -2.5041, -0.5551, 1.0688, -6.1699, 2.9532, 0.2836, -0.2305, -0.2826, -0.2411, -1.683, -0.065, 3.0084, -0.5306, -1.1025, -4.5031, -4.8028, -8.3015, 0.7613, 3.1876, 3.227, -0.2129, -0.206, 3.4182, 2.0943, 0.5722, -1.0078, 3.7019, -0.6004, -5.5889, -2.2144, 1.8189, 0.7424, -1.0957, -2.206, -1.9224, -6.924, -5.0873, -4.2488, 4.4274, -110.9017, 3.286, -2.3163, 4.5918, -0.806, 2.6483, -2.1839, -7.4894, 3.124, 0.8847, -4.4157, -1.3068, -0.4234, -1.5692, -3.0547, -3.2197, 4.7339, -4.7536, -6.5522, -18.2587, -5.5964, 2.8787, 15.0087, -1.5501, -2.6448, 0.2842, -0.7146, -0.7395, -1.7095, 1.0449, -4.6868, -0.5966, -6.2242, -3.3086, -1.2748, 0.8756, -0.1694, -3.0505, 3.9218, -0.2847, -3.6715, -4.0507, 2.8687, -3.6393, -3.2236, -0.7454, 1.0966, -0.8899, -2.4822, 4.4713, 7.0616, -0.5736, -5.6675, -1.4522, -0.851, -0.644, -2.1496, -0.4093, 1.1574, -2.8768, 0.2824, -187.0143, 2.3774, 4.5038, 0.0225, -8.0295, 1.7164, -3.108, 4.8938, -0.0921, 0.6982, 3.083, 0.4531, -4.643, -3.997, -3.0392, 0.1492, 3.5827, -3.4011, -5.3066, -2.1388, -1.9465, 2.8024, 0.6133, -3.045, -3.5145, -0.8116, -1.9821, 3.5516, 0.7294, 3.221, -0.5667, -0.6342, 1.7577, -2.7836, -0.3848, 0.7789, -2.6399, -0.1458, -1.1263, 28.1519, -17.231, -0.1557, 1.269, -2.3301, 2.9808, -2.0533, -4.7363, -0.8477, -5.427, 4.5266, -12.1554, 0.9369, -0.6581, 2.1541, 1.7792, -27.6513, 1.2925, 5.525, -0.2335, 2.7091, -7.0244, -1.8525, -0.3336, -1.7608, 0.0068, -1.7291, -3.3918, 5.6573, -2.0098, -1.4288, 275.9832, -0.5001, -2.0321, -2.8731, 0.6401, -2.0764, 1.3181, 25.8739, 5.6926, -3.5663, 0.0541, -1.488, -2.1329, 1.2613, -4.7321, -1.9796, 0.0437, -2.8623, -1.5581, 1.9286, -0.9079, 3.9153, 0.7037, 2.0444, -2.3725, -0.6362, -7.8773, -1.5089, 5.3923, -52.8936, 0.4887, -3.9926, 2.6221, -2.977, -3.0209, -0.9707, 0.3014, -2.555, -1.6932, -2.0278, -0.364, -7.2376, -3.2569, -2.1477, -4.5182, 1.3328, 1.9762, 1.6744, -4.2811, 2.0497, -2.4114, -2.5006, -1.4078, 4.98, -0.6131, -5.0006, -0.1463, 0.5088, -2.7464, 0.4027, -5.4485, 3.8764, 1.8128, 0.3668, -4.4052, -4.6812, 0.6721, -2.0058, 5.9598, 2.4843, -0.6738, 0.3305, 1.9467, 11.2707, 1.1854, -2.7161, -4.8744, 0.0032, -0.1365, -0.8412, -2.8866, 4.8051, -3.0147, -1.6669, -1.141, 4.0844, 3.2137, -1.8954, -1.0619, 153.7971, 1.2827, 0.9081, -2.787, -8.5442, 1.2674, -1.6427, -2.8648, -1.3769, -3.7937, -1.7023, -0.261, 12.1764, -1.1635, 4.3324, -0.7186, -2.0226, -0.2684, -3.6854, 1.022, -4.2129, -3.6972, 0.1161, -4.8765, -4.5248, 0.829, -1.7655, -1.8126, 1.0165, -0.6897, -1.4052, -0.972, -0.1975, 1.0464, -1.0231, 1.8305, -4.0287, 5.1546, -1.6322, 2.1342, 1.1775, -1.4964, 2.7585, -3.4385, 0.4723, -2.3592, -1.0929, -5.7301, 3.4966, -7.3801, -1.5586, 1.92, -0.0607, -2.4969, -5.4082, -1.5776, -2.1628, -9.6319, 1.7528, -7.9874, -1.7966, -5.9596, 2.5582, 0.973, -1.9637, 3.8487, 2.8131, -3.5405, -1.4547, 2.0714, -2.4892, -5.0138, 1.6379, -3.1083, -3.6245, 0.2508, -2.3918, 1.4345, -2.9107, 0.8659, -2.4206, -3.9067, -0.0983, -1.1112, -1.4257, -0.9586, -5.2355, -5.7714, -0.1127, -2.7267, -316.7319, -2.218, -20.5943, 0.9108, -1.2262, 1.0783, -2.2452])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_raw.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-8.905, -1.0862, -2.3691, -2.4398, 0.4785, 1.3584, -0.0204, -3.4286, 0.0893, -5.0467, -2.7868, -1.943, -4.5616, -1.877, 0.1455, -0.683, -6.8402, -0.8811, 0.0863, 2.1469, -0.6907, -1.8613, -1.8928, -2.6137, -1.7581, -4.1871, 5.5578, -0.6783, -1.4994, -2.0294, -3.2583, 3.0772, -1.8332, -0.4847, -1.7484, -0.8587, -1.8655, -4.8651, 0.6835, 0.4524, -3.7302, 2.8247, -2.8471, -8.1269, -0.49, 4.0189, 0.9128, -5.351, 0.2942, 0.6564, -2.1262, 3.7597, -6.2351, -3.1916, -0.0423, -0.3187, -3.8299, -1.8902, -1.3944, 0.0147, 3.9087, 6.2884, -4.2914, -0.2979, -3.4832, -2.6943, -1.8861, -1.5141, -1.0729, 1.1266, 3.3515, 0.635, 5.0638, 0.2888, -0.2625, 0.0451, 1.033, -0.3722, -4.3399, -1.0839, -0.3435, -0.4474, -0.2621, -6.8436, -2.7884, 0.5715, -6.7303, -0.0909, 1.2687, -3.9399, -2.4905, -1.7824, 0.7307, 1.677, 1.1691, -5.1921, -2.4675, 2.2127, -0.0777, 0.4576, -1.941, 5.31, -0.78, -1.6557, -4.19, 3.8528, -0.9497, 0.3038, 0.7929, -0.5758, -0.1041, 3.7151, 0.6644, 0.974, -0.6626, -5.1711, 0.4461, 0.5316, -3.6263, 1.7122, 1.1085, -4.7189, -0.5982, -1.0964, 2.2112, 1.5603, -2.7559, 6.3056, -2.6137, 1.1036, -2.0456, -4.8007, 0.3272, -2.14, -4.5566, -4.7928, -6.366, 0.819, -1.7446, 0.0426, -2.5897, 1.2849, 3.3857, -0.371, -0.0991, -3.3352, 1.4395, 4.2038, -1.7932, -1.659, 2.2408, 0.7348, -1.8726, 3.9535, -0.0213, 2.0483, -0.1571, -2.6112, -3.7534, 3.6533, 3.9267, -0.942, 1.1149, -3.454, 2.7971, -2.1083, -1.5012, 0.7224, -0.5835, 1.2324, 1.884, -1.2025, 3.0894, -0.3071, -3.2472, -1.8466, -1.9473, 3.395, -0.8908, 5.0385, -0.4865, 0.439, -3.665, -4.8345, -0.3954, 3.6127, -3.0699, 2.7978, -1.6186, -0.2108, -1.4818, -0.2901, 4.2732, -2.1247, 0.4093, -0.2486, -0.9891, -1.3738, -2.4076, 0.0674, -0.1689, -3.6277, -3.1136, -1.2218, 1.5257, -1.28, -0.9611, -3.6241, 3.1817, -1.214, -1.6249, -3.8706, 0.7152, 1.7666, -1.1341, 4.1968, -1.129, 1.5931, -0.0198, -7.12, 0.5801, -2.2891, 5.7968, -0.446, -5.1388, -1.5334, 0.7875, -0.3661, 1.2299, -3.1498, -1.3478, -2.1688, -1.7484, -0.2115, -2.6373, -0.3737, -0.148, 1.508, -2.4589, -2.6734, 2.1731, 0.2661, 0.9886, 1.032, 0.4937, -0.457, -0.217, 1.2558, -2.2298, -1.6076, -1.0576, -1.6388, -2.1317, -5.3484, 3.4083, -0.1286, -0.8417, -0.9545, 0.5681, -3.2471, -3.7292, 3.1023, -2.0114, -0.5058, -4.0854, 2.4897, -1.1648, -1.3093, -2.4452, 2.1887, -1.4344, -1.2917, 0.969, 0.4279, 3.1803, -2.61, 0.3264, 2.8397, 2.0784, -2.1263, -2.8284, 1.3596, -0.9174, -4.755, -0.9866, -2.3665, 3.0951, 4.7132, 0.8813, 7.0405, -0.3215, -0.6892, -5.162, -2.107, -3.0945, 2.077, -4.2336, -0.4754, 0.1494, 1.3834, 1.8545, 3.5246, 0.6794, 1.1411, 3.716, -0.6161, -0.8078, -0.5545, -0.7866, 2.0577, 2.2055, -10.9223, -1.593, -0.7358, -2.6815, -1.8709, -7.4231, -1.6203, -0.9832, -0.9635, 0.2154, -2.6049, -3.0921, -3.7577, 4.0911, 2.545, 0.3043, -2.2712, -2.2756, -0.4478, -2.8307, 1.7612, -1.1337, 2.7761, 0.2822, 2.0035, -2.0648, -2.5009, -2.6489, 0.2065, 1.9212, 1.1467, 0.8065, 8.2127, -2.3485, -0.953, 2.3167, 0.7502, -1.1769, -5.154, 0.1333, -4.941, 1.7967, 5.2592, -0.0774, -4.0587, 1.5487, -3.5761, -0.1383, 1.7276, 0.4472, -7.7654, -2.1326, -11.2297, 1.9233, 8.6428, 1.7496, 0.3406, -0.2031, 1.0542, -4.6403, -3.5146, -3.1564, -0.3709, -1.1664, 2.3838, 0.692, -1.0232, 2.5721, -2.2718, 1.6402, -2.0944, -0.268, -1.7742, -0.8985, -1.4089, 2.7234, -1.4176, 0.6689, 2.3338, 3.3005, -4.7079, -0.5349, -4.945, -2.4348, 0.0707, -1.4911, -0.0349, -1.0024, -2.4749, -2.2184, -1.4992, -0.692, -3.593, -1.7402, 0.5798, 2.1819, -1.3605, -3.163, -2.737, 6.9195, -0.2446, 1.0872, 0.9327, -0.1655, 4.0972, -4.1915, 1.0895, -4.0303, -0.9682, -1.0125, -0.5438, -4.0717, -1.2517, 0.459, -0.2867, 1.4585, -1.6036, -1.3156, 0.0923, -1.2137, 0.5067, -0.8541, 2.6891, -2.6428, -2.2087, 3.8546, -2.7711, 2.1853, 6.9819, 2.2162, -1.6814, 0.4668, -2.6736, 5.2734, -2.6636, -4.6917, -4.235, -2.2091, 2.2902, -3.5744, -1.9126, -2.7414, 0.0697, 0.5881, -4.517, 1.9149, -0.3417, -0.7117, 2.6272, -0.4286, 0.1487, 2.5459, -5.3127, 0.0205, -2.028, -2.2467, 0.4885, -2.1157, -1.7246, -0.3676, 2.2587, -1.2141, -1.8183, -1.1709, 1.6818, -0.1068, 3.8264, -0.6548, -2.9307, 2.1485, 0.6884, -4.1088, 4.8411, -0.337, -1.2751, 0.1841, -2.0894, -3.967, -0.6366, -1.7799, -3.2262, 0.4965, 2.287, -0.4434, -7.6188, 1.4039, -2.321, -0.8617, 0.2369, 0.3434, 2.1929, 0.3584, -0.6139, 0.5598, -2.4647, -0.6406, -7.2146, 11.0531, -0.7018, 1.0384, -3.101, 1.7161, -1.5322, -1.1212, -0.8293, -2.8716, -0.1203, -1.4238, -0.736, 2.2798, -2.1968, 0.9821, 5.3246, -1.7111, -1.2278, 0.0781, 0.4269, -1.3273, -1.784, -1.6627, -0.4089, 1.2946, -2.8286, -0.0333, 0.2468, 0.0527, 3.3952, -3.6074, -2.6812, -1.6523, -0.1681, -1.6276, -9.5035, 1.3224, -1.012, 2.3217, 0.6978, 1.9703, -4.6353, 0.074, -1.0803, -1.0735, 0.9543, 3.1398, -1.2204, -4.4244, -1.6801, 0.2939, 3.2249, -4.4327, 1.9674, 0.1672, 0.7651, 1.5319, -3.5175, -2.2167, 3.3884, -2.5756, 5.6062, 1.4939, 0.3368, -2.2039, -2.2994, -1.7386, 0.8871, 0.1174, -5.899, -1.6156, -4.7108, 0.427, -4.6695, 2.5138, -0.9076, 0.2639, -0.2346, -6.0487, 1.7931, -3.2268, -1.6753, 0.3283, -3.6639, 0.3864, -0.5597, 0.6363, 0.7297, -0.9683, -0.3224, 7.6872, -2.8716, -0.7515, -1.6037, 1.2574, 3.1972, -7.8098, -1.1887, 0.5279, -0.563, 3.3104, -0.4848, 4.173, 1.4916, 0.2315, 1.9579, 0.159, 2.8471, -0.3901, -0.7537, -2.2426, -1.6719, -0.0045, -0.4692, -6.2487, 0.394, 2.0663, -1.064, 4.4743, -4.0562, 0.983, 0.9279, 2.1331, -0.4291, -0.8678, 6.5443, 1.1979, -1.8114, -1.7962, -3.0158, -0.7954, -8.933, 4.6309, -0.2154, -0.2396, -1.5991, -2.3193, -0.7807, 0.9903, -2.5847, 2.879, 0.4428, -0.176, -0.387, -0.1942, -1.1139, -0.0468, 4.5779, -1.1264, -1.2212, -4.7883, -6.2627, -6.0495, 0.5041, 4.2045, 2.037, -0.2691, -0.2048, 2.968, 1.1583, 0.9573, -0.6147, 2.8894, -0.5433, -6.9171, -1.8379, 2.0008, 0.3109, -0.9428, -2.0432, -3.2062, -3.6597, -5.0899, -5.5109, 3.2639, -2.8075, 4.3974, -1.5098, 2.993, -0.6556, 1.4588, -1.8969, -3.6659, 1.4862, 0.6198, -3.7315, -1.2108, -0.9736, -3.3788, -2.4848, -1.7416, 7.5306, -5.8149, -1.7473, -3.1952, -5.9648, 1.592, 3.1797, -3.0793, -2.4497, 0.1881, -1.1301, -0.8097, -1.2904, 0.5523, -2.5353, -1.1893, -2.8729, -3.0676, -0.4881, 0.7411, -0.1364, -1.9572, 2.0231, -0.2294, -2.43, -3.1616, 1.5518, -2.4455, -3.2005, -0.6071, 0.9194, -0.8313, -1.8964, 2.0638, 4.4575, -0.5436, -5.2092, -1.6483, -0.7825, -0.3404, -1.9144, -0.6523, 0.7426, -1.8752, 0.2451, -11.4378, 1.7945, 2.6485, 0.0234, -7.6596, 1.7343, -2.3196, 2.5245, -0.0687, 0.5147, 1.5914, 0.5515, -3.3412, -5.4689, -1.8537, 0.1453, 1.6536, -2.3827, -2.8048, -1.5184, -1.2687, 1.6474, 0.74, -1.2176, -2.3492, -0.7917, -4.6547, 2.889, 0.8681, 2.0666, -0.3267, -0.3868, 0.9721, -7.4319, -0.1848, 0.6209, -2.2528, -0.1298, -0.88, 9.7257, -3.7943, -0.1423, 1.2451, -3.9055, 2.4005, -2.2818, -3.7769, -0.7675, -3.9027, 2.7114, -2.3464, 0.4952, -0.387, 1.9204, 1.1416, -2.3879, 2.0407, 4.4043, -0.2062, 3.4004, -6.4564, -1.1498, -0.214, -2.436, 0.0076, -2.5959, -1.8758, 3.3887, -2.1, -0.8868, 5.4795, -0.6686, -1.0744, -4.8736, 0.6026, -2.8565, 1.6112, 11.8383, 3.6524, -1.885, 0.0965, -1.2223, -2.3065, 4.0763, -2.3795, -1.6425, 0.0356, -2.921, -0.9997, 0.9175, -0.701, 1.1968, 0.506, 1.5437, -0.8218, -0.2914, -4.3984, -0.6965, 3.2889, -2.8678, 0.6294, -2.2554, 0.9573, -1.3741, -3.5799, -0.8127, 0.2056, -2.2746, -1.2633, -1.4949, -0.3473, -4.0027, -3.062, -2.2591, -3.4117, 1.6775, 1.2058, 0.7231, -6.643, 2.1544, -2.46, -1.1542, -1.0749, 4.0923, -0.5181, -2.3789, -0.5385, 0.3048, -5.3039, 0.3276, -3.141, 1.9997, 1.0244, 0.3924, -1.6439, -2.5322, 0.6941, -2.3611, 1.5097, 1.3438, -0.4253, 0.212, 1.5841, 2.9572, 0.8086, -1.8517, -2.6967, 0.0036, -0.1293, -0.3883, -3.0695, 3.833, -2.6626, -0.8602, -1.9456, 2.5782, 2.7405, -1.0022, -0.914, 3.4148, 0.8741, 1.6017, -3.9467, -3.6896, 0.701, -2.016, -4.2457, -0.7938, -3.4051, -0.7609, -0.1805, 8.1795, -2.8419, 1.803, -1.0819, -1.2115, -0.1881, -4.5818, 0.7903, -3.7814, -3.8198, 0.2734, -3.1287, -4.9736, 0.5651, -1.3015, -1.1634, 1.2303, -0.5934, -0.3755, -0.7337, -0.2877, 0.1888, -0.7635, 0.896, -3.2456, 6.2401, -1.1905, 1.4131, 0.8993, -1.1032, 2.6125, -3.9068, 0.2982, -2.744, -0.9736, -3.617, 2.9275, -3.9008, -0.8804, 0.5296, -0.0383, -2.3484, -5.3757, -0.8138, -1.5359, -5.4429, 1.3532, -1.7887, -2.0811, -0.7955, 0.7146, 0.6342, -1.7338, 2.0819, 1.4511, -2.1975, -1.3192, 1.392, -2.9968, -5.0846, 1.0339, -3.6809, -1.2274, 0.1957, -1.3228, 0.8907, -2.0391, 0.6383, -1.4229, -2.5075, -0.0556, -0.9486, -1.3702, -0.5187, -1.608, -1.8962, -0.0978, -0.9955, -2.9228, -1.4899, -4.9695, 0.4814, -1.74, 0.8416, -1.6751])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_scl.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "Once the model is trained, we can perform predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds = lr_model_raw.predict(ml_data_test.map(lambda lpoint: lpoint.features))\n",
    "scl_preds = lr_model_scl.predict(ml_data_test_scl.map(lambda lpoint: lpoint.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_preds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_preds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving and Persistence\n",
    "\n",
    "Many times, once we train our model, we save it and the load it in oder programs to make predictions. We try first the internal format of Spark, which allows us to save and load a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/lr_model_raw\n",
    "lr_model_raw.save(sc, \"../data/lr_model_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_raw_loaded = LogisticRegressionModel.load(sc, \"../data/lr_model_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds_loaded = lr_model_raw_loaded.predict(ml_data_test.map(lambda lpoint: lpoint.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_preds_loaded.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "MLlib includes some functionalities to calculate automatically some metrics of trained ML models. While there are more, here we will evaluate the LR model of the spam classification section using the `BinaryClassificationMetrics` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (1000,[18,133,184,278,390,403,411,421,574,581,630,637,706,783,789,807,808,821,822,824,937],[1.87243028944,17.2517364161,8.62586820804,8.62586820804,8.62586820804,17.2517364161,8.62586820804,8.62586820804,8.62586820804,4.24016829583,8.62586820804,8.62586820804,17.2517364161,0.993951694971,8.62586820804,8.62586820804,8.62586820804,2.46045035381,8.62586820804,17.2517364161,8.62586820804]))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label_lr = ml_data_test.map(lambda lpoint: (float(lr_model_raw.predict(lpoint.features)), lpoint.label))\n",
    "metrics_lr = BinaryClassificationMetrics(pred_label_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR model\n",
      "Area Under PR: 0.5086440719665847\n",
      "Area Under ROC: 0.8401651325124242\n"
     ]
    }
   ],
   "source": [
    "print(\"LR model\")\n",
    "print(\"Area Under PR: {0}\".format(metrics_lr.areaUnderPR))\n",
    "print(\"Area Under ROC: {0}\".format(metrics_lr.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Spark ML\n",
    "\n",
    "Now, we are going to see some of the capabilities offered by the Spark ML package, which works with DataFrames instead that MLlib that works with RDDs. In particular, we are going to do again the spam classification problem using two Pipelines: one for the data preparation and the other one for the ML model.\n",
    "\n",
    "### Data Preparation: Data Encoding & Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, IDF, SQLTransformer, StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.pipeline import Pipeline, PipelineModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----+----+----+\n",
      "|label|                text| _c2| _c3| _c4|\n",
      "+-----+--------------------+----+----+----+\n",
      "|  ham|Go until jurong p...|null|null|null|\n",
      "|  ham|Ok lar... Joking ...|null|null|null|\n",
      "| spam|Free entry in 2 a...|null|null|null|\n",
      "|  ham|U dun say so earl...|null|null|null|\n",
      "|  ham|Nah I don't think...|null|null|null|\n",
      "| spam|FreeMsg Hey there...|null|null|null|\n",
      "|  ham|Even my brother i...|null|null|null|\n",
      "|  ham|As per your reque...|null|null|null|\n",
      "| spam|WINNER!! As a val...|null|null|null|\n",
      "| spam|Had your mobile 1...|null|null|null|\n",
      "|  ham|I'm gonna be home...|null|null|null|\n",
      "| spam|SIX chances to wi...|null|null|null|\n",
      "| spam|URGENT! You have ...|null|null|null|\n",
      "|  ham|I've been searchi...|null|null|null|\n",
      "|  ham|I HAVE A DATE ON ...|null|null|null|\n",
      "| spam|XXXMobileMovieClu...|null|null|null|\n",
      "|  ham|Oh k...i'm watchi...|null|null|null|\n",
      "|  ham|Eh u remember how...|null|null|null|\n",
      "|  ham|Fine if that��s t...|null|null|null|\n",
      "| spam|England v Macedon...|null|null|null|\n",
      "+-----+--------------------+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ini_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_select = SQLTransformer(statement = \"SELECT label, text FROM __THIS__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_filter = SQLTransformer(statement = \"SELECT * from __THIS__ WHERE text is not null AND label is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"text\", outputCol = \"text_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_text = SQLTransformer(statement = \"SELECT *, size(text_token) as count FROM __THIS__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = HashingTF(numFeatures = 1000, inputCol = \"text_token\", outputCol = \"text_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol = \"text_tf\", outputCol = \"text_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "assember = VectorAssembler(inputCols = [\"text_features\", \"count\"],\n",
    "                           outputCol = \"features_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_pipeline_model = Pipeline(stages=[sql_select, sql_filter, label_indexer, \n",
    "                                      tokenizer, count_text, tf, idf, assember, scaler]).fit(ini_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_pipe = etl_pipeline_model.transform(ini_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  ham|(1001,[7,77,150,1...|\n",
      "|  ham|(1001,[20,316,484...|\n",
      "| spam|(1001,[30,35,73,1...|\n",
      "|  ham|(1001,[57,368,372...|\n",
      "|  ham|(1001,[135,163,32...|\n",
      "| spam|(1001,[25,36,91,9...|\n",
      "|  ham|(1001,[18,47,48,5...|\n",
      "|  ham|(1001,[36,71,92,2...|\n",
      "| spam|(1001,[39,43,61,7...|\n",
      "| spam|(1001,[36,73,82,1...|\n",
      "|  ham|(1001,[26,41,106,...|\n",
      "| spam|(1001,[15,35,36,4...|\n",
      "| spam|(1001,[68,73,122,...|\n",
      "|  ham|(1001,[19,36,39,1...|\n",
      "|  ham|(1001,[44,82,170,...|\n",
      "| spam|(1001,[41,43,49,6...|\n",
      "|  ham|(1001,[275,426,44...|\n",
      "|  ham|(1001,[80,147,236...|\n",
      "|  ham|(1001,[159,170,29...|\n",
      "| spam|(1001,[9,19,45,71...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_data_pipe.select(\"label\", \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_pipe_train, ml_data_pipe_test = ml_data_pipe.randomSplit(weights=[0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4477"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_pipe_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1096"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_pipe_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark ML Models\n",
    "\n",
    "Once we have our data cleaned and encoded, we can now train a ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_num\", regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline(stages=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline_model = lr_pipeline.fit(ml_data_pipe_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in any other pipeline, we can access to one of the steps, and its metadata. Here we get the coefficientMatrix of the trained LR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(3, 1001, [0.0199, -0.0057, -0.003, 0.019, 0.0014, -0.0079, 0.021, 0.0274, ..., -0.0005, -0.0001, -0.0002, -0.0003, -0.0003, -0.0001, -0.0002, -0.0009], 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline_model.stages[0].coefficientMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Persistence and Spark ML\n",
    "\n",
    "We can save and load our pipelines (including both data transformers and ML algorithms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/etl_pipeline_model\n",
    "!rm -rf ../data/lr_pipeline_model\n",
    "etl_pipeline_model.save(\"../data/etl_pipeline_model\")\n",
    "lr_pipeline_model.save(\"../data/lr_pipeline_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_pipeline_load = PipelineModel.load(\"../data/etl_pipeline_model\")\n",
    "lr_pipeline_load = PipelineModel.load(\"../data/lr_pipeline_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_pipeline_load.transform(etl_pipeline_load.transform(ini_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|label_num|prediction|\n",
      "+---------+----------+\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"label_num\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated Model Selection: Parameter Search\n",
    "\n",
    "Spark ML offers some functionalities to perform hiperparameter tunning on ML models. Let's check our previous problem testing different regularization parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_num\", regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_pipeline = Pipeline(stages=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder().addGrid(LogisticRegression.regParam, [0.1, 0.01, 0.05]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label_num\", rawPredictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=estimator_pipeline,\n",
    "                          estimatorParamMaps=param_grid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = crossval.fit(dataset=ml_data_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|label_num|prediction|\n",
      "+---------+----------+\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      0.0|       0.0|\n",
      "|      1.0|       1.0|\n",
      "+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_model.transform(ml_data_pipe).select(\"label_num\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
