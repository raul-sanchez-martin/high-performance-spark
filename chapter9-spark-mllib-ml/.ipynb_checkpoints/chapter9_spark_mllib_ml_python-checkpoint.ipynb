{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Spark MLlib and ML\n",
    "\n",
    "In this notebook, we will see the main capabilities of Spark MLlib and ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark-MLlib-ML\").master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with MLlilb\n",
    "\n",
    "In this section, we will focus on MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector, SparseVector\n",
    "from pyspark.mllib.feature import HashingTF, Word2Vec, IDF, StandardScaler, ChiSqSelector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib Feature Encoding and Data Preparation\n",
    "\n",
    "#### Working with Spark Vectors\n",
    "\n",
    "We can create Dense Vectors, Sparse Vectors and Labeled Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_vector = DenseVector(np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 2.0, 3.0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vector = SparseVector(4, {0:1.5, 2:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 1.5, 2: 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_point = LabeledPoint(1, dense_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, [1.0,2.0,3.0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Textual Data\n",
    "\n",
    "We can also prepare text data using some in-built data transformations capabilities already included in MLlib. We first prepare some text data about Spam and Non-Spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_data = spark.read.csv(\"../data/spam.csv\", header=True)\n",
    "ini_data_rdd = ini_data.select([\"label\", \"text\"]).rdd.filter(lambda row: (isinstance(row.label, str) and isinstance(row.text, str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5573"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_data_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label='ham', text='Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_data_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rdd = ini_data_rdd.map(lambda x: x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the `HashingTF` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasing_TF(text_rdd):\n",
    "    \"\"\"\n",
    "    Transforms an input RDD of text using the Hashing TF transformer\n",
    "    \n",
    "    :input text_rdd: input RDD\n",
    "    :return: transformed RDD\n",
    "    \"\"\"\n",
    "    tokenizer = HashingTF()\n",
    "    text_tokenized = text_rdd.map(lambda text: text.split(\" \"))\n",
    "    return tokenizer.transform(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_text = hasing_TF(text_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(1048576, {79172: 1.0, 244892: 1.0, 296409: 1.0, 312753: 1.0, 384022: 1.0, 407924: 1.0, 414297: 1.0, 442668: 1.0, 627241: 1.0, 639697: 1.0, 799074: 1.0, 856522: 1.0, 897134: 1.0, 901549: 1.0, 968035: 1.0, 988036: 1.0, 997716: 1.0, 1015964: 1.0, 1033917: 1.0, 1044354: 1.0})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_text.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasing_TF_with_text(text_rdd):\n",
    "    \"\"\"\n",
    "    Transforms an input RDD of text using the Hashing TF transformer\n",
    "    keeping also the original text\n",
    "    \n",
    "    :input text_rdd: input RDD\n",
    "    :return: transformed RDD\n",
    "    \"\"\"\n",
    "    tokenizer = HashingTF()\n",
    "    return text_rdd.map(lambda text: (text, tokenizer.transform(text.split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_text_perserving = hasing_TF_with_text(text_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "  SparseVector(1048576, {79172: 1.0, 244892: 1.0, 296409: 1.0, 312753: 1.0, 384022: 1.0, 407924: 1.0, 414297: 1.0, 442668: 1.0, 627241: 1.0, 639697: 1.0, 799074: 1.0, 856522: 1.0, 897134: 1.0, 901549: 1.0, 968035: 1.0, 988036: 1.0, 997716: 1.0, 1015964: 1.0, 1033917: 1.0, 1044354: 1.0}))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_text_perserving.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `Word2Vec` transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenized = text_rdd.map(lambda text: text.split(\" \"))\n",
    "word2vec_trformer = Word2Vec().fit(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.0222, -0.004, 0.0507, -0.019, -0.0542, -0.0246, -0.0323, -0.0121, 0.0243, -0.032, 0.0457, 0.0128, 0.0131, 0.0493, -0.0092, -0.0428, 0.0212, -0.0189, -0.0174, -0.0058, 0.0433, -0.0109, 0.0427, -0.0408, -0.0133, -0.0025, 0.0695, -0.0366, 0.0426, -0.0134, -0.0358, -0.023, 0.0397, -0.0394, 0.0227, 0.0193, 0.0633, 0.0817, 0.0049, -0.0593, 0.02, -0.0286, 0.0041, 0.0782, -0.0041, 0.0282, -0.059, -0.0303, -0.0037, 0.0536, -0.0201, 0.0277, -0.0814, -0.0039, -0.0408, -0.0377, -0.0498, -0.011, -0.0811, -0.0062, 0.0452, 0.0137, 0.0732, 0.058, -0.0503, 0.1328, -0.0513, 0.0283, 0.072, 0.0248, -0.0583, 0.0237, -0.0077, -0.0393, 0.0518, 0.0384, -0.0365, -0.0185, -0.0642, -0.0187, 0.0401, 0.0066, -0.0481, 0.0099, 0.0663, -0.0221, -0.0621, -0.0067, -0.1254, 0.0442, 0.0699, -0.0168, -0.0043, 0.018, 0.0314, 0.0414, 0.0143, 0.0309, 0.0767, 0.0346])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_trformer.transform(\"great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.0012, -0.0069, 0.0451, -0.019, 0.0113, -0.0161, -0.031, -0.0115, 0.0074, -0.0253, 0.0227, 0.0062, 0.0023, 0.0275, -0.0088, 0.012, 0.0383, 0.0084, 0.0547, 0.0096, 0.0477, -0.0309, -0.0034, -0.0159, -0.0136, -0.0069, 0.0255, 0.006, -0.0123, -0.0202, -0.0004, 0.0161, 0.0058, -0.0089, 0.0104, -0.0086, -0.0024, 0.0089, -0.0013, 0.0127, 0.0038, -0.0176, -0.0229, 0.0123, 0.0175, 0.0352, -0.0346, -0.0239, -0.0125, 0.0126, 0.038, 0.0167, -0.0497, -0.0183, -0.0321, -0.0239, 0.0038, 0.0037, -0.0211, -0.0095, 0.0328, 0.0064, -0.0146, 0.0024, 0.0125, 0.0065, -0.0544, 0.0047, 0.0561, 0.0046, 0.0083, -0.0018, -0.0259, 0.0232, 0.0123, 0.0021, -0.0434, -0.0162, -0.0582, -0.0282, 0.0065, 0.0094, -0.0182, 0.0136, 0.0149, -0.0163, -0.0231, -0.0161, -0.048, -0.0051, 0.0386, 0.0169, 0.0113, 0.0152, 0.0124, 0.0481, 0.0064, -0.0004, -0.0051, -0.0103])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_trformer.transform(\"Free\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Data for Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = HashingTF(1000)\n",
    "tf_vectors = tf.transform(text_rdd)\n",
    "idf = IDF()\n",
    "idf_model = idf.fit(tf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_text = ini_data_rdd.filter(lambda row: row.label == \"spam\").map(lambda row: row.text.split(\" \"))\n",
    "gen_text = ini_data_rdd.filter(lambda row: row.label != \"spam\").map(lambda row: row.text.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_points = idf_model.transform(tf.transform(spam_text)).map(lambda x: LabeledPoint(1, x))\n",
    "gen_points = idf_model.transform(tf.transform(gen_text)).map(lambda x: LabeledPoint(0, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_ini = spam_points.union(gen_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data = ml_data_ini.map(lambda row: (randint(0,100), row)).sortByKey().map(lambda row: row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_train, ml_data_test = ml_data.randomSplit(weights = [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[54] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_train.cache()\n",
    "ml_data_test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling and Selection\n",
    "\n",
    "It is useful sometimes for the ML algorithms to scale that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler()` --> to scale numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler_model = std_scaler.fit(ml_data.map(lambda lpoint: lpoint.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = ml_data_train.map(lambda lpoint: lpoint.label)\n",
    "test_label = ml_data_test.map(lambda lpoint: lpoint.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_train_scl = train_label.zip(std_scaler_model.transform(ml_data_train.map(lambda lpoint: lpoint.features)))\\\n",
    ".map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "\n",
    "ml_data_test_scl = test_label.zip(std_scaler_model.transform(ml_data_test.map(lambda lpoint: lpoint.features)))\\\n",
    ".map(lambda x: LabeledPoint(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (1000,[51,98,119,174,278,287,289,300,403,477,483,495,529,581,670,783,809,853,859,870,872,895,976],[9.17147586322,7.42399720804,3.45425747689,5.51614801053,8.56298964927,6.23128041373,1.86079465498,3.1673723595,3.52179269018,15.9460499929,7.4596187541,2.12420580213,14.1328441425,3.59083843089,11.0516323062,2.87708423949,17.2367161587,11.7008405545,6.85324302967,2.34265780804,4.46649798562,10.8133983969,7.2839340914]))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_train_scl.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (1000,[170,260,363,394,562,597,598,622,629,636,677,682,699,737,772,780,803,827,866,903],[11.0516323062,5.05119022394,1.62660099221,6.10844968699,11.047722177,8.55999869183,5.51614801053,6.74081779345,6.79881631632,8.01796068006,9.3131464278,11.7008405545,5.42244927422,9.3814194486,7.24821974818,10.108220851,6.87217595581,2.66911570937,11.2979706501,3.47586227908]))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_test_scl.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ChiSqSelector` --> to select the most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ChiSqSelector(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_model = selector.fit(ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.mllib.feature.ChiSqSelectorModel at 0x7fe1ad4b6c88>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_train_sel = train_label.zip(selector_model.transform(ml_data_train.map(lambda lpoint: lpoint.features)))\\\n",
    ".map(lambda x: LabeledPoint(x[0], x[1]))\n",
    "\n",
    "ml_data_test_sel = test_label.zip(selector_model.transform(ml_data_test.map(lambda lpoint: lpoint.features)))\\\n",
    ".map(lambda x: LabeledPoint(x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (100,[3,12,25,27,46,71,82,84,93],[8.62586820804,8.62586820804,0.0939834678827,8.62586820804,8.62586820804,8.62586820804,0.993951694971,25.8776046241,8.62586820804]))]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_train_sel.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (100,[16,33,61,73,76,80,86,94],[8.62586820804,0.0621731829742,8.62586820804,8.62586820804,8.62586820804,8.62586820804,8.62586820804,0.0771763495663]))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_test_sel.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib Model Training\n",
    "\n",
    "Once we have prepared our data, we can train some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionWithLBFGS()\n",
    "lr_model_raw = lr.train(ml_data_train)\n",
    "lr_model_scl = lr.train(ml_data_train_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-2.6086, -4.8151, -3.9921, -1.1688, -0.0367, 18.8321, 0.6745, -4.3258, -3.2294, -2.2899, -0.4485, -3.0772, -3.3741, -2.6127, 0.574, -2.4362, -3.6972, -1.0446, 9.9425, 2.7657, 3.5532, -3.7996, 2.0916, -5.0304, -3.9207, -9.0825, 2.3378, 3.9537, -1.0363, -11.3515, -2.6287, 30.6823, -4.0409, 0.7543, -2.8899, -3.0697, -0.6833, -2.2942, -2.1847, 4.4067, -2.4156, 4.2431, -0.0712, -3.7738, 1.3988, 7.6198, 6.2064, -5.9746, 0.8384, 8.5136, -8.6159, 3.8864, -2.0624, -4.6018, 2.801, 1.5305, -3.4478, 0.555, -1.443, 2.1376, 3.0497, 10.2418, -0.6784, -0.4287, -1.8162, -3.5604, -5.7638, -1.6088, -3.4644, 2.6326, 4.8454, -0.0129, 5.2212, 1.2538, 1.1603, 3.4528, 2.1786, -2.4778, -2.629, -1.4906, -0.1491, 2.6019, 0.6794, -2.7756, -5.0355, -0.7124, -6.4041, 0.2431, 1.1633, -0.2067, -3.8111, -3.0373, 43.8725, 0.2153, 0.1234, -4.7272, -3.6907, 43.9328, 0.9895, 3.7785, 2.8709, 1.6141, -1.5827, 0.9475, -219.3317, 4.6197, -3.9421, 1.4826, -2.4069, -2.7477, 4.1786, 11.4708, -0.347, 5.4015, -2.0308, -3.7215, 3.5219, -0.4115, -47.9656, 0.2399, -1.4892, -13.5516, -2.1454, -0.1842, 6.2509, 3.2983, -4.8235, 6723.7399, -7.2271, 1.3996, -0.2675, -3.6861, -4.1427, -5.6737, -1.5307, -7.0218, -110.6618, 2.4024, -1.2553, 0.538, -1.5957, 2.1265, 5.0913, -1.2748, -6.6467, -7.3413, -2.6051, 1.797, -1.9477, -16.9408, 6.1748, 0.9049, -62.4988, 7.6972, -5.5973, -1.2922, 1.7422, -4.3047, -16.6627, 2.3865, 8.3451, -6.257, 13.6151, -2.8392, 0.7394, -4.9688, -4.3592, 0.7701, -0.5162, -1.682, 2.7303, 1.3111, 0.531, -5.797, -4.8692, -0.7246, -0.4449, 6.0571, 0.0603, 7.2339, -2.665, 5.1486, -1.9091, -19.8866, -1.874, 5.2327, -3.4885, 4.6296, -2.777, -2.3845, -4.4892, 3.0, 5.7015, -9.8001, 0.9208, 0.3262, -2.5339, -6.1509, -5.5564, -1.4139, 0.5627, -179.0049, -3.7721, -2.8457, 1.5183, 1.7605, 1.4672, 1.4167, 7.2591, -4.9424, -2.6283, -6.2582, 2.9046, 2.3908, -5.1092, 6.138, -4.1627, 1.8783, 0.0353, -7.6659, -2.6174, -3.104, 1.8029, 1.187, -0.6888, -2.0282, 2.2195, -3.2419, 2.852, 0.4692, -2.7632, -12.2483, -4.9963, 0.3928, -2.1649, -1.3254, -0.8668, 2.3272, -5.6392, -4.0878, -0.0293, -2.3198, -0.2602, 1.636, 2.0182, 0.3469, 0.3926, 2.845, -5.508, -10.5524, -1.8843, -1.4008, 4.8941, -3.991, 14.6776, 1.6837, -1.6892, -0.2656, 3.125, -8.0016, -1.6874, 5.308, 1.3116, -1.7952, -259.9031, 7.074, -1.4293, -4.3965, -4.6174, -2.5985, -2.1605, -4.7506, 3.9318, -4.8298, 2.4661, -2.0238, 0.4625, 5.6428, 0.9801, -1.4327, -25.9969, -0.0176, -0.6921, -3.508, 0.5797, -0.5309, 6.637, 2.5984, 7.311, 158.359, -2.2357, -3.2189, -1.3532, -3.7473, -4.1058, 4.6903, -5.5913, -1.5536, 13.605, 0.9837, 1.5456, 0.2761, 4.3735, 0.7884, 10.8153, -1.8844, -2.4072, 3.9006, -0.6252, 2.0824, 1.8771, -100.8648, -3.2478, -2.9393, -3.5965, -1.4684, -3.1453, -0.5046, 0.572, -18.2021, 0.1322, -1.1571, -3.2669, -1.8056, 9.6386, 2.1621, -1.6877, -3.775, -4.4498, -4.9894, -3.5956, 2.7482, 2.7236, 0.2378, -2.1544, 3.0611, -1.7114, -3.2432, -3.1872, -0.0443, 3.1015, -1.3548, -0.8121, 4.0201, -3.6825, -0.5535, 3.9901, -3.7286, -3.9903, -6.3392, -1.0358, -6.0233, 7.7631, 8.0118, 2.1687, -6.1792, 6.6894, -0.252, 3.0218, 4.7063, 5.585, -5.3874, 0.3644, -470.463, 0.8352, 1.4317, 6.0262, -1.4798, -0.4185, -0.6395, -0.7389, -2.3441, -8.4952, -0.8631, -0.6197, -1.0653, 3.8412, -1.7306, 4.8745, -2.0768, 3.9983, -1.1716, 1.5029, -2.2779, -4.7683, 0.1935, -1.8907, -0.4654, 9.0612, 3.7152, 3.9722, -5.5266, -0.067, -6.3885, -14.0592, -0.021, -1.145, 2.041, -1.5095, -1.23, -2.8128, -1.1703, 2.2255, -1.9025, -0.2292, 3.1577, 2.8213, 5.9688, -4.6404, -2.0238, 3.7895, -5.8849, 8.9991, -3.607, 1.1148, 3.2534, -6.1379, 1.0701, -6.336, 0.8674, 1.8678, -0.0228, -0.3197, -2.9253, 3.5039, 1.9514, 5.7328, -0.2853, -2.1965, 1.0985, -2.7476, 2.7699, -5.0559, 0.4693, -2.9269, -5.5588, 17.6815, -0.5282, 3.0068, 8.0526, 2.4399, -0.3684, 1.9766, 5.5575, 7.6376, -2.6744, -2.862, -2.5106, -6.3257, 2.2687, -1.3362, 0.0547, -1.2552, -1.3069, 1.0184, -2.893, 0.1405, -6.746, -14.2946, 2.6396, -0.0505, -2.565, 1.1522, -5.3239, -1.066, -0.5867, -2.0385, -1.7761, -3.7713, -2.6419, -0.4561, 0.897, 1.6545, -1.5786, -2.962, 5.1734, -0.0686, 11.8118, -5.0149, 0.1122, -0.2636, 0.295, -5.9214, 4.4792, -1.9225, -0.4102, 2.1875, -6.5442, -5.0962, -0.0427, 0.3916, -14.677, -0.7321, 3.2675, 2.2748, -4.2287, -0.3124, -2.3443, -1.3275, 0.6216, -2.9929, 1.1349, -2.8071, -14.3362, -2.4612, -5.0476, 3.721, -3.989, 28.2173, -5.1122, 4.7252, -11.3897, 8.0748, 0.0414, 2.8084, -4.0282, -5.1089, -1.2542, -2.4838, -8.4197, 1.5716, -1.1477, 2.6199, 7.4278, -62.0582, -3.5407, 0.839, 2.7012, 0.0666, -5.3108, -0.6251, -2.9068, -1.162, 1.4418, -1.2502, 1.1915, -3.1041, 2.3548, -6.6373, -3.9826, -1.8602, -1.2628, 3.1582, -8.6969, 7.7564, -1.91, 0.5116, -0.5701, 1.4826, -5.2701, 2.808, -0.2148, -0.9265, 2.8591, 3.4901, 0.2619, -56.9928, -2.3073, -1.2034, 3.897, -1.8538, 6.4586, 2.3971, -2.4565, 1.0041, -5.3569, -4.5911, 6.8986, -53.8, 5.0677, 6.6531, -0.1067, -2.9949, -4.2494, -2.2958, 1.7443, -4.1415, -6.3605, -1.9982, -1.3902, -2.4965, -13.9427, 4.6543, -1.1847, -1.4474, 1.1632, -4.7532, -0.028, -5.5869, -2.7893, -2.7459, -7.5137, -0.2181, -2.6171, -4.1641, -1.5012, 1.669, -2.0995, 8.3151, -4.2175, -0.9256, -1.2564, 0.917, 1.6197, -1.7256, -1.765, 1.7222, -1.4411, 3.3563, -3.5462, 9.7024, 1.5563, 0.4534, 0.2317, 0.8389, 0.1529, 0.8748, -2.3313, -4.0267, -0.2162, 1.1635, -1.4212, -6.457, -1.1538, 4.4287, -0.8061, 2.675, -2.5588, 1.9334, 0.816, 5.2969, -1.0063, -1.0903, 8.8648, 1.0711, -0.8969, -3.5336, -3.3402, -1.5467, -5.7778, 4.0825, 0.9456, -3.051, -0.4298, -3.1753, -1.5439, 0.8449, -5.9278, 7.8862, -3.1208, 0.5988, 0.4061, 2.6884, -1.5835, -3.5871, 5.7606, -1.9245, 0.9128, -3.4788, -5.0124, -5.7934, -2.7838, 1.9656, 5.5627, 1.4387, -2.5643, 2.2302, 0.7679, 0.0928, -8.1583, 6.5583, 2.0531, -5.36, -2.7719, 0.8456, 4.0243, 1.0344, -2.1139, -1.471, -7.4339, -5.2881, -7.6227, 5.1863, -148.4778, 1.4442, -1.4938, 5.3372, -1.1932, 1.3083, -0.7559, -12.0531, 6.4142, 3.3754, -5.4899, -0.4635, -2.0317, -3.7929, -1.607, 1.7531, 5.884, -6.3852, -8.1677, -6.0342, -7.969, 6.9344, 22.9105, -2.0553, 1.6806, -0.9903, -1.5831, 0.4443, -2.6923, 1.7941, -4.4606, -0.0815, -13.7373, -4.8651, 5.5101, 3.9434, 0.9938, -2.3507, 2.9101, 0.1591, -3.5059, -5.2229, -1.512, -2.3257, -2.077, -0.2388, 0.2936, 0.678, 0.597, 1.6974, 6.8457, -3.5463, -6.5814, -3.6217, -0.0376, 0.0778, -1.9783, -0.3363, -3.6412, -1.6442, -0.9034, -238.0101, 0.2093, 4.8987, -3.7143, -4.7254, -0.0228, -5.3487, 2.2585, 1.5319, -1.5486, -1.5586, 0.4428, 0.4487, -5.9496, -1.5823, -1.2444, 2.6411, -3.6507, -0.7869, -0.234, -0.4842, 1.9659, 0.4622, -4.4998, -4.3173, -3.6441, -2.6963, 5.3592, -1.0431, 1.0025, 1.4064, 7.7394, 5.4348, -2.1531, -6.452, -2.0349, -6.0774, -0.8368, -1.7353, 22.5592, -5.1696, -2.0542, 2.2809, -3.3329, 5.4314, -2.0908, -6.6869, -2.292, -3.9433, 2.4545, -9.0921, 2.7483, -2.4987, 1.3802, 0.016, -15.4604, 0.4794, 1.735, 0.8982, 5.8791, -8.6499, -3.6824, -2.7944, -0.8033, 1.3744, -1.7677, -4.1204, -2.0252, -3.6328, 0.8573, 238.9848, -1.4601, -1.2441, -4.7289, 3.9237, -3.074, -0.906, 28.0563, 6.2737, -3.4994, 0.7462, -0.2738, -4.3909, 1.8229, -7.2513, -3.5674, 1.6757, -2.8304, 0.8996, 5.7536, -1.659, 5.8261, -0.7247, 3.6261, -2.8375, 3.1366, -10.934, -2.2618, 0.4904, -48.4688, 0.5351, -5.9275, 3.7091, -2.7467, -4.2907, 0.3369, 3.2094, -3.3312, -1.9954, -1.335, -1.3921, -8.7465, -5.5598, -3.3385, -5.9316, -1.4232, 0.4574, 4.1804, -4.7579, 2.8693, -2.1734, -6.4078, -3.147, 7.8363, 5.2185, 1.7203, -0.4185, -2.3542, -2.483, 0.8874, -10.1384, 2.4347, 5.0833, -3.5523, -10.2382, -2.4624, -2.3008, -3.6227, 13.2696, 0.6041, -2.3333, -2.701, 0.2899, 16.8247, 3.5538, -2.5429, -1.0391, -1.8407, -2.4849, 1.0043, -3.0851, 5.8019, -0.2379, -1.4854, -1.6105, 4.3208, 1.3604, -0.772, 0.1666, 230.9893, 3.8243, 0.5446, -5.9704, -5.7202, 3.4883, -2.813, -2.0306, 1.3719, -3.4232, 1.3597, -3.1752, 12.9994, -1.4874, 5.8385, -1.7922, -0.542, 0.2423, -3.3372, 1.637, -5.4921, -5.2834, -1.9119, -7.6619, -3.1349, -4.7905, -0.2595, -4.8801, -1.2012, -1.3743, -6.4957, -2.6155, 0.105, 10.9034, 4.2554, 7.627, -2.2528, 4.719, 2.7294, 2.8723, 2.8611, -2.4502, 1.1345, -4.4534, -0.6115, -1.0308, -2.338, -4.885, 3.4232, -5.7336, -1.1061, 1.408, 1.4744, -2.54, -5.9812, -8.1311, -4.0974, -7.4236, 1.5105, -7.7454, -2.8115, -7.6935, -8.2454, 1.601, -2.1273, -2.9956, 4.0144, -5.1535, -2.3105, -1.8229, -2.3611, -5.2395, 5.5023, -4.4775, -7.0187, -1.2025, -2.0301, 5.4961, -4.4461, 2.4122, -2.7271, -2.9329, -1.1446, 1.3535, 0.0617, 0.4714, -4.1528, 2.1411, 1.6178, -3.7719, -704.9956, -7.2516, -24.177, -4.0707, -0.9538, -1.2966, -0.4543])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_raw.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-11.4511, -3.2815, -3.6537, -3.0673, -0.0372, 2.034, 0.4188, -2.5438, -2.7318, -2.8168, -0.2831, -1.8089, -7.0138, -1.8566, 0.4482, -1.9633, -8.2874, -1.2621, 2.0454, 2.0141, 2.4223, -2.3583, 1.4849, -2.9582, -2.7843, -5.5397, 2.2975, 3.853, -1.2892, -9.68, -3.1039, 5.3005, -2.6745, 0.677, -2.1045, -2.7339, -0.7638, -4.5957, -1.4675, 2.6887, -2.2734, 3.2028, -0.0844, -12.9716, 1.0567, 4.7294, 3.1208, -5.4078, 0.702, 4.1672, -4.7462, 3.6552, -7.1768, -4.1374, 1.2928, 1.1824, -4.7474, 0.8878, -1.0377, 1.5948, 3.1112, 6.9797, -0.5121, -0.5832, -2.8212, -3.0118, -4.1973, -1.8991, -1.957, 5.4485, 4.8496, -0.0116, 4.8359, 1.6619, 0.9438, 2.5153, 1.4847, -1.6162, -3.5886, -1.1634, -0.4621, 1.6149, 0.6481, -5.0769, -3.0195, -0.2601, -7.9288, 0.1535, 1.0864, -0.3252, -3.2268, -1.8858, 4.6268, 0.2491, 0.1089, -8.5181, -4.2778, 9.1526, 1.1497, 2.4637, 2.1919, 6.176, -0.948, 0.6729, -6.4237, 2.3245, -1.5763, 0.8202, -1.2416, -1.8464, 1.3648, 5.3247, -0.3361, 4.6507, -1.048, -4.5687, 2.4356, -0.2276, -3.7566, 0.599, -1.6727, -4.7041, -1.5428, -0.1078, 2.6014, 1.2537, -2.8355, 6.2386, -5.0666, 1.5313, -0.3188, -6.8545, -3.5008, -5.617, -2.3901, -6.7574, -6.6015, 2.4499, -1.0919, 0.6429, -3.6083, 1.5496, 3.7998, -0.6738, -3.0679, -6.6426, -1.9889, 5.6903, -1.4006, -1.0167, 4.1494, 0.542, -2.7424, 7.2466, -3.4741, -1.1118, 1.4031, -2.6718, -3.9707, 1.9981, 5.3543, -4.5581, 5.1563, -2.8269, 0.8395, -1.5967, -4.8793, 0.3079, -0.3092, -1.2549, 2.131, 0.9665, 0.3239, -4.9895, -7.6142, -1.1962, -0.4676, 5.3497, 0.0295, 4.7151, -1.4086, 2.8474, -1.3194, -4.0695, -1.7097, 3.303, -3.9568, 3.0176, -1.7236, -1.6705, -2.9271, 1.5476, 4.4516, -4.6622, 0.8724, 0.3076, -1.2742, -4.0092, -6.0089, -1.1395, 0.2054, -5.0679, -2.3819, -2.8705, 0.8213, 0.7869, 0.9414, 1.1065, 6.4114, -2.7352, -1.051, -5.465, 2.1427, 1.6529, -6.7542, 5.5558, -2.539, 1.6029, 0.0413, -6.3581, -3.541, -3.0661, 4.9381, 0.5647, -1.6791, -1.4399, 1.1161, -2.476, 3.1476, 0.3242, -4.2773, -4.8977, -4.6626, 0.2861, -3.0209, -0.4329, -0.5564, 2.022, -4.6819, -4.1702, -0.0426, -1.5126, -0.503, 1.3698, 1.3358, 0.2678, 0.3226, 1.2715, -4.8301, -3.0403, -1.1493, -2.0291, 3.6079, -6.965, 6.9825, 0.9763, -1.0838, -0.2287, 1.5301, -3.5763, -2.8816, 3.1806, 0.6766, -1.0753, -4.7712, 5.0219, -0.9022, -2.3783, -4.9166, -1.5276, -1.4314, -3.0965, 2.3981, -4.4424, 2.6697, -2.1909, 0.4659, 5.4303, 0.9873, -1.2217, -4.3218, -0.007, -0.6969, -4.9143, 0.5649, -0.5173, 4.1194, 3.5969, 3.9548, 7.9983, -1.7822, -2.7724, -1.0675, -5.0742, -4.4463, 3.3729, -6.6888, -1.0283, 2.0565, 1.0931, 4.2091, 0.1882, 3.0639, 0.6905, 5.4089, -1.1295, -1.753, 4.3603, -0.5136, 1.73, 1.4188, -11.5752, -2.4796, -3.495, -3.1227, -0.8295, -9.9246, -2.3554, 1.0863, -2.884, 0.2227, -6.7696, -6.4597, -4.178, 6.1884, 1.5559, -0.9533, -3.4744, -2.1169, -3.0432, -4.5055, 2.8556, 1.405, 0.1816, -0.9629, 2.6373, -2.5444, -2.477, -2.7684, -0.025, 1.788, -1.3116, -0.823, 5.6929, -4.2297, -0.6058, 3.0826, -2.5411, -1.9532, -5.8735, -0.5603, -5.228, 4.3853, 5.9773, 1.8345, -6.0279, 3.1823, -0.1814, 1.6346, 2.8191, 4.2157, -8.4888, 0.4285, -17.9824, 0.9378, 8.7467, 3.2598, -2.0757, -0.3122, -0.376, -1.4947, -3.8307, -6.772, -2.2438, -0.44, -0.8925, 1.4024, -1.3796, 4.4891, -1.5134, 1.8455, -0.9054, 1.4959, -1.5959, -4.4164, 0.1262, -1.0457, -0.3826, 4.6743, 4.0895, 4.715, -5.1241, -0.0416, -5.7846, -6.0462, -0.0209, -0.9131, 1.2002, -1.0993, -2.7299, -1.9982, -1.2533, 1.4506, -4.6598, -0.1153, 2.4379, 1.8108, 3.2288, -5.5833, -2.8386, 3.9873, -3.8359, 4.0221, -2.0375, 0.6168, 1.6359, -6.7177, 0.6866, -7.0777, 0.5997, 1.098, -0.0301, -0.2496, -1.3502, 1.9379, 1.7516, 2.8827, -0.3034, -1.4322, 1.2833, -2.8214, 2.1619, -2.1833, 0.5859, -3.7219, -3.6791, 7.3584, -0.72, 3.0299, 6.4874, 1.4343, -0.5832, 2.0912, 3.5081, 5.1323, -2.9864, -2.5723, -2.8354, -3.8582, 2.8292, -1.8258, 0.0462, -1.3498, -1.4472, 0.869, -4.6634, 0.0945, -3.8916, -4.5611, 3.9229, -0.0471, -2.1504, 1.9498, -8.1151, -0.949, -0.3703, -1.3897, -2.3144, -2.217, -2.1074, -0.4506, 0.5471, 1.5927, -1.2981, -2.0199, 2.4611, -0.0403, 6.3895, -2.4547, 0.1316, -0.2288, 0.2253, -2.817, 5.1795, -1.7824, -0.4362, 2.3827, -1.9107, -4.1878, -0.0322, 0.3057, -4.2684, -0.4304, 2.5777, 1.8687, -7.2236, -0.2566, -2.4212, -1.3312, 1.0525, -3.5199, 1.4788, -2.0468, -1.2851, -1.7009, -3.5846, 0.4894, -6.4522, 10.501, -0.9056, 1.8771, -5.1249, 4.0603, 0.0357, 1.8312, -3.2463, -2.569, -0.9364, -1.897, -6.8514, 1.7909, -0.9054, 3.2227, 6.6717, -3.566, -3.9771, 0.4328, 3.1397, 0.0406, -3.2414, -0.6946, -1.2992, -1.2994, 1.2845, -1.1578, 1.0781, -1.6791, 3.565, -4.587, -5.1342, -4.1859, -0.6514, 2.4121, -11.243, 5.924, -1.1441, 0.5383, -1.46, 0.9966, -3.8865, 1.8303, -0.1849, -0.6134, 2.6279, 4.5797, 0.2022, -3.3964, -2.1867, -0.8084, 2.8739, -1.4159, 3.4137, 1.8716, -2.2049, 1.6766, -4.5238, -5.2748, 4.6357, -1.609, 6.5079, 3.6795, -0.0738, -2.0981, -2.7264, -3.3196, 1.4614, -3.3014, -9.1694, -1.3623, -2.2215, -1.222, -8.2319, 3.0805, -2.7931, -0.9723, 0.5849, -6.0479, -0.0492, -4.0177, -2.8864, -1.9011, -6.1722, -0.1609, -3.0912, -3.8361, -1.6682, 2.0437, -2.1157, 13.0027, -3.6995, -0.723, -2.1912, 0.6072, 0.7239, -5.5464, -1.7568, 1.644, -1.0624, 4.3018, -2.5519, 3.8797, 1.2784, 0.2665, 0.1225, 1.3784, 0.2915, 0.8043, -1.1411, -4.526, -0.1776, 0.7221, -0.9553, -8.2626, -0.9753, 3.9209, -0.9563, 1.4139, -5.2069, 2.1724, 1.0353, 2.7997, -1.0841, -0.8135, 8.0847, 0.6418, -1.1598, -3.8015, -5.4101, -1.8604, -12.2077, 5.3704, 0.6886, -2.1374, -0.3355, -2.941, -2.1713, 0.7828, -2.4832, 7.688, -4.8727, 0.4572, 0.5562, 2.1658, -1.0481, -2.5821, 8.7659, -4.0858, 1.0111, -3.6992, -6.5359, -4.2217, -1.8431, 2.5926, 3.5113, 1.8184, -2.5489, 1.9365, 0.4247, 0.1552, -4.976, 5.1188, 1.8577, -6.6338, -2.3006, 0.9302, 1.6852, 0.89, -1.9579, -2.4533, -3.9292, -5.2908, -9.887, 3.8234, -3.7588, 1.9327, -0.9737, 3.4788, -0.9706, 0.7206, -0.6566, -5.8997, 3.0514, 2.3647, -4.6392, -0.4294, -4.6721, -8.167, -1.3072, 0.9483, 9.36, -7.8108, -2.1782, -1.056, -8.4936, 3.835, 4.8538, -4.083, 1.5566, -0.6556, -2.5037, 0.4864, -2.0322, 0.9483, -2.4129, -0.1625, -6.3406, -4.5108, 2.1097, 3.3379, 0.8007, -1.5082, 1.5012, 0.1282, -2.3204, -4.0765, -0.8179, -1.5629, -2.0621, -0.1945, 0.2462, 0.6334, 0.4561, 0.7835, 4.3212, -3.361, -6.0492, -4.1109, -0.0346, 0.0411, -1.7618, -0.5359, -2.3362, -1.0717, -0.7841, -14.5567, 0.158, 2.8807, -3.8621, -4.5077, -0.023, -3.9919, 1.165, 1.1433, -1.1416, -0.8045, 0.539, 0.3229, -8.1405, -0.9651, -1.2122, 1.219, -2.5576, -0.4159, -0.1661, -0.3156, 1.1557, 0.5576, -1.7993, -2.8858, -3.5549, -6.332, 4.3594, -1.2414, 0.6432, 0.8108, 4.7205, 3.0057, -5.7486, -3.0992, -1.6221, -5.1862, -0.745, -1.3558, 7.7936, -1.1384, -1.8777, 2.238, -5.5863, 4.3741, -2.3234, -5.3324, -2.0753, -2.8357, 1.4702, -1.7551, 1.4526, -1.4694, 1.2304, 0.0102, -1.3351, 0.7569, 1.3831, 0.7933, 7.3794, -7.9505, -2.2855, -1.7929, -1.1113, 1.5209, -2.6539, -2.2788, -1.2131, -3.7959, 0.5321, 4.7449, -1.9519, -0.6578, -8.0215, 3.694, -4.2289, -1.1075, 12.8369, 4.0253, -1.8496, 1.3328, -0.2249, -4.7485, 5.891, -3.6463, -2.9599, 1.3631, -2.8885, 0.5772, 2.7372, -1.2808, 1.7809, -0.5211, 2.738, -0.9829, 1.4365, -6.1052, -1.044, 0.2991, -2.6279, 0.6891, -3.3484, 1.3542, -1.2678, -5.0847, 0.2821, 2.1887, -2.9657, -1.4887, -0.9841, -1.3285, -4.8372, -5.2272, -3.5116, -4.4789, -1.7913, 0.2791, 1.8052, -7.383, 3.0159, -2.2172, -2.9576, -2.4027, 6.4395, 4.4099, 0.8184, -1.5408, -1.4101, -4.7953, 0.7219, -5.8447, 1.256, 2.8725, -3.8002, -3.8205, -1.332, -2.3763, -4.2644, 3.3613, 0.3268, -1.4728, -1.733, 0.2359, 4.4144, 2.4243, -1.7336, -0.5749, -2.0455, -2.3543, 0.4636, -3.2805, 4.6282, -0.2101, -0.7665, -2.7463, 2.7274, 1.1601, -0.4082, 0.1434, 5.1288, 2.6063, 0.9606, -8.4547, -2.4702, 1.9292, -3.4523, -3.0095, 0.7909, -3.0726, 0.6077, -2.1952, 8.7323, -3.6329, 2.4298, -2.6984, -0.3247, 0.1698, -4.1489, 1.2659, -4.9296, -5.4586, -4.5022, -4.9159, -3.4459, -3.2659, -0.1913, -3.1322, -1.4539, -1.1824, -1.7356, -1.9743, 0.1529, 1.9674, 3.176, 3.7332, -1.8149, 5.7128, 1.9908, 1.9017, 2.1852, -1.8063, 1.0744, -5.0599, -0.3861, -1.1989, -2.0829, -3.0836, 2.8661, -3.0305, -0.6248, 0.3884, 0.9307, -2.3889, -5.9453, -4.1945, -2.9098, -4.195, 1.1662, -1.7345, -3.2567, -1.027, -2.3032, 1.0436, -1.8782, -1.6204, 2.0709, -3.1986, -2.0953, -1.2249, -2.8427, -5.3135, 3.4732, -5.3024, -2.3769, -0.9386, -1.1227, 3.4125, -3.1148, 1.7783, -1.6031, -1.8824, -0.6466, 1.1554, 0.0593, 0.2551, -1.2755, 0.7035, 1.4042, -1.3771, -6.5056, -4.8713, -5.834, -2.1516, -1.3534, -1.012, -0.3389])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_scl.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "\n",
    "Once the model is trained, we can perform predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds = lr_model_raw.predict(ml_data_test.map(lambda lpoint: lpoint.features))\n",
    "scl_preds = lr_model_scl.predict(ml_data_test_scl.map(lambda lpoint: lpoint.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_preds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scl_preds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving and Persistence\n",
    "\n",
    "Many times, once we train our model, we save it and the load it in oder programs to make predictions. We try first the internal format of Spark, which allows us to save and load a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/lr_model_raw\n",
    "lr_model_raw.save(sc, \"../data/lr_model_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_raw_loaded = LogisticRegressionModel.load(sc, \"../data/lr_model_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds_loaded = lr_model_raw_loaded.predict(ml_data_test.map(lambda lpoint: lpoint.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_preds_loaded.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "MLlib includes some functionalities to calculate automatically some metrics of trained ML models. While there are more, here we will evaluate the LR model of the spam classification section using the `BinaryClassificationMetrics` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, (1000,[51,98,119,174,278,287,289,300,403,477,483,495,529,581,670,783,809,853,859,870,872,895,976],[8.62586820804,8.62586820804,8.62586820804,8.62586820804,8.62586820804,8.62586820804,0.0939834678827,8.62586820804,8.62586820804,8.62586820804,8.62586820804,3.62865593428,8.62586820804,2.12008414791,8.62586820804,0.993951694971,25.8776046241,8.62586820804,8.62586820804,8.62586820804,8.62586820804,8.62586820804,8.62586820804]))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label_lr = ml_data_test.map(lambda lpoint: (float(lr_model_raw.predict(lpoint.features)), lpoint.label))\n",
    "metrics_lr = BinaryClassificationMetrics(pred_label_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR model\n",
      "Area Under PR: 0.5788418237362521\n",
      "Area Under ROC: 0.8663442556970273\n"
     ]
    }
   ],
   "source": [
    "print(\"LR model\")\n",
    "print(\"Area Under PR: {0}\".format(metrics_lr.areaUnderPR))\n",
    "print(\"Area Under ROC: {0}\".format(metrics_lr.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, IDF, SQLTransformer, StringIndexer\n",
    "from pyspark.ml.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----+----+----+\n",
      "|label|                text| _c2| _c3| _c4|\n",
      "+-----+--------------------+----+----+----+\n",
      "|  ham|Go until jurong p...|null|null|null|\n",
      "|  ham|Ok lar... Joking ...|null|null|null|\n",
      "| spam|Free entry in 2 a...|null|null|null|\n",
      "|  ham|U dun say so earl...|null|null|null|\n",
      "|  ham|Nah I don't think...|null|null|null|\n",
      "| spam|FreeMsg Hey there...|null|null|null|\n",
      "|  ham|Even my brother i...|null|null|null|\n",
      "|  ham|As per your reque...|null|null|null|\n",
      "| spam|WINNER!! As a val...|null|null|null|\n",
      "| spam|Had your mobile 1...|null|null|null|\n",
      "|  ham|I'm gonna be home...|null|null|null|\n",
      "| spam|SIX chances to wi...|null|null|null|\n",
      "| spam|URGENT! You have ...|null|null|null|\n",
      "|  ham|I've been searchi...|null|null|null|\n",
      "|  ham|I HAVE A DATE ON ...|null|null|null|\n",
      "| spam|XXXMobileMovieClu...|null|null|null|\n",
      "|  ham|Oh k...i'm watchi...|null|null|null|\n",
      "|  ham|Eh u remember how...|null|null|null|\n",
      "|  ham|Fine if that��s t...|null|null|null|\n",
      "| spam|England v Macedon...|null|null|null|\n",
      "+-----+--------------------+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ini_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_select = SQLTransformer(statement = \"SELECT label, text FROM __THIS__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_filter = SQLTransformer(statement = \"SELECT * from __THIS__ WHERE text is not null AND label is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"text\", outputCol = \"text_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = HashingTF(numFeatures = 1000, inputCol = \"text_token\", outputCol = \"text_tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"text_tf\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipeline = Pipeline(stages=[sql_select, sql_filter, label_indexer, tokenizer, tf, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipeline_model = ml_pipeline.fit(ini_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|label|                text|label_num|          text_token|             text_tf|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  ham|Go until jurong p...|      0.0|[go, until, juron...|(1000,[7,77,150,1...|(1000,[7,77,150,1...|[46.1925496142281...|[1.0,9.5478469531...|       0.0|\n",
      "|  ham|Ok lar... Joking ...|      0.0|[ok, lar..., joki...|(1000,[20,316,484...|(1000,[20,316,484...|[22.7239392220272...|[0.99999999999972...|       0.0|\n",
      "| spam|Free entry in 2 a...|      1.0|[free, entry, in,...|(1000,[30,35,73,1...|(1000,[30,35,73,1...|[-49.707099745267...|[5.78975520257700...|       1.0|\n",
      "|  ham|U dun say so earl...|      0.0|[u, dun, say, so,...|(1000,[57,368,372...|(1000,[57,368,372...|[51.7359225992089...|[1.0,5.3440271207...|       0.0|\n",
      "|  ham|Nah I don't think...|      0.0|[nah, i, don't, t...|(1000,[135,163,32...|(1000,[135,163,32...|[38.6006856216011...|[1.0,3.0544816603...|       0.0|\n",
      "+-----+--------------------+---------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_pipeline_model.transform(ini_data).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
