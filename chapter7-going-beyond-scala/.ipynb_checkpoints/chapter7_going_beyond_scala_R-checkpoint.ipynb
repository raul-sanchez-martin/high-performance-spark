{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count Example Using SparkR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘SparkR’ was built under R version 3.4.4”\n",
      "Attaching package: ‘SparkR’\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cov, filter, lag, na.omit, predict, sd, var, window\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.data.frame, colnames, colnames<-, drop, endsWith, intersect,\n",
      "    rank, rbind, sample, startsWith, subset, summary, transform, union\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(SparkR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spark package found in SPARK_HOME: /usr/local/spark\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching java with spark-submit command /usr/local/spark/bin/spark-submit   sparkr-shell /tmp/RtmpzfJmmB/backend_port1b84a6bab27 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Java ref type org.apache.spark.sql.SparkSession id 1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparkR.session(appName = \"word-count-exampleR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- read.text(\"../data/README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|      # Apache Spark|\n",
      "|                    |\n",
      "|Spark is a fast a...|\n",
      "|high-level APIs i...|\n",
      "|supports general ...|\n",
      "|rich set of highe...|\n",
      "|MLlib for machine...|\n",
      "|and Spark Streami...|\n",
      "|                    |\n",
      "|<http://spark.apa...|\n",
      "|                    |\n",
      "|                    |\n",
      "|## Online Documen...|\n",
      "|                    |\n",
      "|You can find the ...|\n",
      "|guide, on the [pr...|\n",
      "|This README file ...|\n",
      "|                    |\n",
      "|   ## Building Spark|\n",
      "|                    |\n",
      "+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "showDF(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words <- selectExpr(df, \"split(value, \\\" \\\") as words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>words</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>#     , Apache, Spark </td></tr>\n",
       "\t<tr><td></td></tr>\n",
       "\t<tr><td>Spark    , is       , a        , fast     , and      , general  , cluster  , computing, system   , for      , Big      , Data.    , It       , provides </td></tr>\n",
       "\t<tr><td>high-level, APIs      , in        , Scala,    , Java,     , Python,   , and       , R,        , and       , an        , optimized , engine    , that      </td></tr>\n",
       "\t<tr><td>supports   , general    , computation, graphs     , for        , data       , analysis.  , It         , also       , supports   , a          </td></tr>\n",
       "\t<tr><td>rich        , set         , of          , higher-level, tools       , including   , Spark       , SQL         , for         , SQL         , and         , DataFrames, </td></tr>\n",
       "\t<tr><td>MLlib      , for        , machine    , learning,  , GraphX     , for        , graph      , processing,</td></tr>\n",
       "\t<tr><td>and        , Spark      , Streaming  , for        , stream     , processing.</td></tr>\n",
       "\t<tr><td></td></tr>\n",
       "\t<tr><td>&lt;http://spark.apache.org/&gt;</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " words\\\\\n",
       "\\hline\n",
       "\t \\#     , Apache, Spark \\\\\n",
       "\t \\\\\n",
       "\t Spark    , is       , a        , fast     , and      , general  , cluster  , computing, system   , for      , Big      , Data.    , It       , provides \\\\\n",
       "\t high-level, APIs      , in        , Scala,    , Java,     , Python,   , and       , R,        , and       , an        , optimized , engine    , that      \\\\\n",
       "\t supports   , general    , computation, graphs     , for        , data       , analysis.  , It         , also       , supports   , a          \\\\\n",
       "\t rich        , set         , of          , higher-level, tools       , including   , Spark       , SQL         , for         , SQL         , and         , DataFrames, \\\\\n",
       "\t MLlib      , for        , machine    , learning,  , GraphX     , for        , graph      , processing,\\\\\n",
       "\t and        , Spark      , Streaming  , for        , stream     , processing.\\\\\n",
       "\t \\\\\n",
       "\t <http://spark.apache.org/>\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "words | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| #     , Apache, Spark  | \n",
       "|  | \n",
       "| Spark    , is       , a        , fast     , and      , general  , cluster  , computing, system   , for      , Big      , Data.    , It       , provides  | \n",
       "| high-level, APIs      , in        , Scala,    , Java,     , Python,   , and       , R,        , and       , an        , optimized , engine    , that       | \n",
       "| supports   , general    , computation, graphs     , for        , data       , analysis.  , It         , also       , supports   , a           | \n",
       "| rich        , set         , of          , higher-level, tools       , including   , Spark       , SQL         , for         , SQL         , and         , DataFrames,  | \n",
       "| MLlib      , for        , machine    , learning,  , GraphX     , for        , graph      , processing, | \n",
       "| and        , Spark      , Streaming  , for        , stream     , processing. | \n",
       "|  | \n",
       "| <http://spark.apache.org/> | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   words                                                                                                                                                                 \n",
       "1  #     , Apache, Spark                                                                                                                                                 \n",
       "2                                                                                                                                                                        \n",
       "3  Spark    , is       , a        , fast     , and      , general  , cluster  , computing, system   , for      , Big      , Data.    , It       , provides               \n",
       "4  high-level, APIs      , in        , Scala,    , Java,     , Python,   , and       , R,        , and       , an        , optimized , engine    , that                  \n",
       "5  supports   , general    , computation, graphs     , for        , data       , analysis.  , It         , also       , supports   , a                                   \n",
       "6  rich        , set         , of          , higher-level, tools       , including   , Spark       , SQL         , for         , SQL         , and         , DataFrames, \n",
       "7  MLlib      , for        , machine    , learning,  , GraphX     , for        , graph      , processing,                                                                \n",
       "8  and        , Spark      , Streaming  , for        , stream     , processing.                                                                                          \n",
       "9                                                                                                                                                                        \n",
       "10 <http://spark.apache.org/>                                                                                                                                            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "take(words, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "explodedWords <- select(words, alias(explode(words$words), \"words\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>words</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>#      </td></tr>\n",
       "\t<tr><td>Apache </td></tr>\n",
       "\t<tr><td>Spark  </td></tr>\n",
       "\t<tr><td>       </td></tr>\n",
       "\t<tr><td>Spark  </td></tr>\n",
       "\t<tr><td>is     </td></tr>\n",
       "\t<tr><td>a      </td></tr>\n",
       "\t<tr><td>fast   </td></tr>\n",
       "\t<tr><td>and    </td></tr>\n",
       "\t<tr><td>general</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " words\\\\\n",
       "\\hline\n",
       "\t \\#      \\\\\n",
       "\t Apache \\\\\n",
       "\t Spark  \\\\\n",
       "\t        \\\\\n",
       "\t Spark  \\\\\n",
       "\t is     \\\\\n",
       "\t a      \\\\\n",
       "\t fast   \\\\\n",
       "\t and    \\\\\n",
       "\t general\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "words | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| #       | \n",
       "| Apache  | \n",
       "| Spark   | \n",
       "|         | \n",
       "| Spark   | \n",
       "| is      | \n",
       "| a       | \n",
       "| fast    | \n",
       "| and     | \n",
       "| general | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   words  \n",
       "1  #      \n",
       "2  Apache \n",
       "3  Spark  \n",
       "4         \n",
       "5  Spark  \n",
       "6  is     \n",
       "7  a      \n",
       "8  fast   \n",
       "9  and    \n",
       "10 general"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "take(explodedWords, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc <- agg(groupBy(explodedWords, \"words\"), \"words\" = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>words</th><th scope=col>count(words)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>online       </td><td>1            </td></tr>\n",
       "\t<tr><td>graphs       </td><td>1            </td></tr>\n",
       "\t<tr><td>[\"Parallel   </td><td>1            </td></tr>\n",
       "\t<tr><td>[\"Building   </td><td>1            </td></tr>\n",
       "\t<tr><td>thread       </td><td>1            </td></tr>\n",
       "\t<tr><td>documentation</td><td>3            </td></tr>\n",
       "\t<tr><td>command,     </td><td>2            </td></tr>\n",
       "\t<tr><td>abbreviated  </td><td>1            </td></tr>\n",
       "\t<tr><td>overview     </td><td>1            </td></tr>\n",
       "\t<tr><td>rich         </td><td>1            </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " words & count(words)\\\\\n",
       "\\hline\n",
       "\t online        & 1            \\\\\n",
       "\t graphs        & 1            \\\\\n",
       "\t {[}\"Parallel    & 1              \\\\\n",
       "\t {[}\"Building    & 1              \\\\\n",
       "\t thread        & 1            \\\\\n",
       "\t documentation & 3            \\\\\n",
       "\t command,      & 2            \\\\\n",
       "\t abbreviated   & 1            \\\\\n",
       "\t overview      & 1            \\\\\n",
       "\t rich          & 1            \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "words | count(words) | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| online        | 1             | \n",
       "| graphs        | 1             | \n",
       "| [\"Parallel    | 1             | \n",
       "| [\"Building    | 1             | \n",
       "| thread        | 1             | \n",
       "| documentation | 3             | \n",
       "| command,      | 2             | \n",
       "| abbreviated   | 1             | \n",
       "| overview      | 1             | \n",
       "| rich          | 1             | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   words         count(words)\n",
       "1  online        1           \n",
       "2  graphs        1           \n",
       "3  [\"Parallel    1           \n",
       "4  [\"Building    1           \n",
       "5  thread        1           \n",
       "6  documentation 3           \n",
       "7  command,      2           \n",
       "8  abbreviated   1           \n",
       "9  overview      1           \n",
       "10 rich          1           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "take(wc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
